{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. GAN\n",
    "This section will be an exercise. Surprisingly, you can build GAN fairly easily just by using the concepts we learned so far.\n",
    "\n",
    "## Preparation\n",
    "Read section 1, 2, 3 of the original [GAN paper](https://arxiv.org/pdf/1406.2661.pdf). Then, follow the next 7 steps to implement GAN.\n",
    "\n",
    "To summarie, we have the following problem setup:\n",
    "- $x$: data with distribution $p_{data}$\n",
    "- $p_g$: distribution trained by the generator\n",
    "- $z$: prior input noise variables\n",
    "- $p_z$: prior of $z$\n",
    "- $G(z;\\theta_G)$: generator neural network with parameter $\\theta_G$\n",
    "- $D(z;\\theta_D)$: discriminator neural network with parameter $\\theta_D$\n",
    "\n",
    "The goal for $D,G$ are the following:\n",
    "- $D$: $max_D V(D) = E_{x\\sim p_{data}}(x)[logD(x)] + E_{z\\sim p_z(z)}[log(1-D(G(z))]$\n",
    "- $G$: $min_G V(G) = E_{z\\sim p_z(z)}[log(1-D(G(z))]$\n",
    "\n",
    "### 1. Implement generator and discriminator.\n",
    "Let both G and D be a 1-hidden layer fully connected neural network. Use ReLU for activation function and let the hidden layer size be 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the inputs to generator and discriminator.\n",
    "- Input to G: (batch size) $\\times$ dim(z)\n",
    "- Input to D: (batch size) $\\times$ dim(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build D and G computation graph.\n",
    "For D, you should have two inputs: real data and fake data, which is the output of $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define the objective.\n",
    "Expectation should be approximated using the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Minimize (or maximize) the objective.\n",
    "Adam optimizer is recommended. We should have two optimizers for D and G. Be careful to only take the gradient with respect to the variables to optimize. Namely\n",
    "- $V(D)$: weights and biases of D\n",
    "- $V(G)$: weights and biases of G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train the model.\n",
    "For each iteration, take some batch of MNIST. Generate a prior noise $z$ by `np.random.uniform(-1., 1., size=[batch_size, noise_dim])`. Feed the batch data and prior noise to the model to update the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training, for each noise generated, get the output $x$ and plot it using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. If not done already, use TensorBoard to check the computation graph and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_workshop]",
   "language": "python",
   "name": "conda-env-tensorflow_workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
