{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Basic Math, Matrix Operations\n",
    "\n",
    "In this section, we'll cover some basic operations in TensorFlow. There are many more cool operations not covered here. For a more holistic overview, see [the official API documentation](https://www.tensorflow.org/api_docs/python/tf#functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 5\n",
      "b: 8\n",
      "c: 30\n",
      "d: 15\n",
      "e: 1024\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(2,3)       # 2 + 3\n",
    "b = tf.subtract(10,2) # 10 - 2\n",
    "c = tf.multiply(3,10) # 3 * 10\n",
    "d = tf.div(30,2)      # 30 / 2\n",
    "e = tf.pow(2,10)      # 2 ** 10\n",
    "\n",
    "with tf.Session() as sess: # Evaluate the result\n",
    "    print('a:',sess.run(a))\n",
    "    print('b:',sess.run(b))\n",
    "    print('c:',sess.run(c))\n",
    "    print('d:',sess.run(d))\n",
    "    print('e:',sess.run(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `tf.constant` to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 8\n",
      "b: 9\n",
      "c: 17\n",
      "d: -1\n",
      "e: 98\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(8)\n",
    "b = tf.constant(9)\n",
    "c = a + b\n",
    "d = a - b\n",
    "e = 10 * b + a\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('a:',sess.run(a))\n",
    "    print('b:',sess.run(b))\n",
    "    print('c:',sess.run(c))\n",
    "    print('d:',sess.run(d))\n",
    "    print('e:',sess.run(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's wrong with the following?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Const_3:0\", shape=(), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e7ee2c26ae91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## This throws an error ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/tensorflow_workshop/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow_workshop/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow_workshop/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow_workshop/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    547\u001b[0m     raise ValueError(\n\u001b[1;32m    548\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    550\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Const_3:0\", shape=(), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "f = tf.constant(2)\n",
    "g = tf.constant(3.0)\n",
    "## This throws an error ##\n",
    "h = f * g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type should match for operations to be valid. There are data types like `int32`, `float32`, and `float64`. **In general, use `float32`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1) Implement the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function). \n",
    "\n",
    "2) Evalaute the result for some values.\n",
    "\n",
    "3) (optional) Plot the sigmoid function using the TensorFlow outputs.\n",
    "\n",
    "4) Repeat the above for [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "# def relu(x):\n",
    "#     return tf.maximum(0.0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #2\n",
    "# with tf.Session() as sess:\n",
    "#     for x in [0.0, 1.0, 2.0]:\n",
    "#         print(sess.run(sigmoid(x)))\n",
    "#         print(sess.run(relu(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3\n",
    "# with tf.Session() as sess:\n",
    "#     def sigmoid_run(i):\n",
    "#         return sess.run(sigmoid(i))\n",
    "#     def relu_run(i):\n",
    "#         return sess.run(relu(i))\n",
    "\n",
    "#     nums = np.arange(-6.0,6.0,1)\n",
    "#     sigmoid_runs = np.vectorize(sigmoid_run)\n",
    "#     sigmoid_nums = sigmoid_runs(nums)\n",
    "\n",
    "#     relu_runs = np.vectorize(relu_run)\n",
    "#     relu_nums = relu_runs(nums)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(sigmoid_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(relu_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_a = tf.constant([[1,2],[3,4],[5,6]]) # this is how you initialize a matrix\n",
    "mat_b = tf.constant([[1,2],[2,3]])       # you can also pass in numpy arrays\n",
    "mat_c = tf.constant([[2,1],[3,2]])\n",
    "\n",
    "mat_dot1 = tf.matmul(mat_a, mat_b)   # matrix dot product\n",
    "mat_dot2 = mat_a @ mat_b             # convenint notation for matrix dot product\n",
    "\n",
    "mat_el1  = tf.multiply(mat_b, mat_c) # element-wise product\n",
    "mat_el2  = mat_b * mat_c             # convenint notation for element-wise product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(mat_a) # you can't know the values, but you can know the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot1:\n",
      " [[ 5  8]\n",
      " [11 18]\n",
      " [17 28]]\n",
      "dot2:\n",
      " [[ 5  8]\n",
      " [11 18]\n",
      " [17 28]]\n",
      "el1:\n",
      " [[2 2]\n",
      " [6 6]]\n",
      "el2:\n",
      " [[2 2]\n",
      " [6 6]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('dot1:\\n',sess.run(mat_dot1))\n",
    "    print('dot2:\\n',sess.run(mat_dot2))\n",
    "    print('el1:\\n',sess.run(mat_el1))\n",
    "    print('el2:\\n',sess.run(mat_el2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_e = tf.constant([[2,1],[3,2]])\n",
    "mat_f = tf.constant([3,4])\n",
    "\n",
    "mat_broad1 = 2 * mat_e     # each element is multiplied by 2\n",
    "mat_broad2 = mat_e * mat_f # each row in mat_e is multiplied by mat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broad1:\n",
      " [[4 2]\n",
      " [6 4]]\n",
      "broad2:\n",
      " [[6 4]\n",
      " [9 8]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('broad1:\\n',sess.run(mat_broad1))\n",
    "    print('broad2:\\n',sess.run(mat_broad2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "How do you multiply each COLUMN in mat_e by mat_f?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broad4:\n",
      " [[ 6  3]\n",
      " [12  8]]\n"
     ]
    }
   ],
   "source": [
    "mat_broad4 = mat_e * tf.transpose(mat_f) # each row in mat_e is multiplied by mat_f\n",
    "with tf.Session() as sess:\n",
    "    print('broad4:\\n',sess.run(mat_broad4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_8:0' shape=(1, 2) dtype=int32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_2:0' shape=(2, 1) dtype=int32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(mat_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_g = tf.constant([[1,2],[1,3]])\n",
    "\n",
    "red_sum_all = tf.reduce_sum(mat_g)            # reduce matrix to a scalar\n",
    "red_sum_row = tf.reduce_sum(mat_g, axis = 0)  # reduce the rows\n",
    "red_sum_col1 = tf.reduce_sum(mat_g, axis = 1) # reduce the columns\n",
    "red_sum_col2 = tf.reduce_sum(mat_g, axis = 1, keep_dims=True) # keep the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:\n",
      " 7\n",
      "row:\n",
      " [2 5]\n",
      "col:\n",
      " [3 4]\n",
      "col:\n",
      " [[3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('all:\\n',sess.run(red_sum_all))\n",
    "    print('row:\\n',sess.run(red_sum_row))\n",
    "    print('col:\\n',sess.run(red_sum_col1))\n",
    "    print('col:\\n',sess.run(red_sum_col2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always, always set keep_dims=True!** It keeps column vectors as column vectors. If you don't do that it might cause some really annoying bugs with broadcastng. Also check out `tf.reduce_mean`, `tf.reduce_max`, etc that are also often used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "1) Say you are given a feature matrix as below (20 samples, 10 features each). Normalize the features (i.e. subtract the mean, divide by the std.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant(np.random.uniform(1,10,[20,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Implement the [softmax function](https://en.wikipedia.org/wiki/Softmax_function).\n",
    "\n",
    "3) Implement ReLU for matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.77236045e-16  -1.72951931e-16   2.77555756e-16   9.99200722e-17\n",
      "  -3.33066907e-16  -3.44169138e-16  -3.10862447e-16   1.11022302e-17\n",
      "  -1.55431223e-16  -2.22044605e-16]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "mean, var = tf.nn.moments(features, axes=[0], keep_dims=True)\n",
    "features_normalized = (features - mean) / var ** (1/2)\n",
    "with tf.Session() as sess:\n",
    "    features_normalized_np = sess.run(features_normalized)\n",
    "print(np.mean(features_normalized_np,axis=0))\n",
    "print(np.std(features_normalized_np,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = tf.exp(x)\n",
    "    sum_exp_x = tf.reduce_sum(exp_x)\n",
    "    return exp_x / sum_exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00214401,  0.0158422 ,  0.11705892,  0.86495489], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([2, 4, 6, 8],dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    softmax_x_np = sess.run(softmax(x))\n",
    "softmax_x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([-2, 4, -6, 8],dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    relu_x_np = sess.run(relu(x))\n",
    "softmax_x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others\n",
    "Here are other operations I use often:\n",
    "- `tf.transpose`: matrix transpose\n",
    "- `tf.equal`: compare matrix element-wise\n",
    "- `tf.argmax`: get the index of max element\n",
    "- `tf.gather, tf.slice`: often used for indexing, see the [official guide](https://www.tensorflow.org/api_guides/python/array_ops#Slicing_and_Joining) for details\n",
    "- `tf.while_loop`: when building a computation graph, don't use python for loop, use this\n",
    "- `tf.zeros, tf.ones`: same as `np.zeros, np.ones`\n",
    "- `tf.random_normal, tf.random_uniform`: randomly sample from distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- Don't use numpy APIs in between when building TensorFlow graphs because it will not be part of your computation graph.\n",
    "- If there is a numpy way to do it, there is usually a tf way to do it.\n",
    "- If you think an operation is too complicated, code it up in numpy first, then convert it to tensorflow. Check if the two outputs match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_workshop]",
   "language": "python",
   "name": "conda-env-tensorflow_workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
